{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "incidence.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcMurVac8jsARVr2eO+kXG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmelberg/health-analytics-using-python/blob/master/incidence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lhiQiwRCVA3"
      },
      "source": [
        "## Estimating incidence of a disease based on patient registry data: Dealing with lookback and lookahead bias \n",
        "\n",
        "# Hans Olav Melberg, University of Oslo, 21. October, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt39xM4gC7MV"
      },
      "source": [
        "\n",
        "### Lookback bias\n",
        "A key limitation when estimating disease incidence using data from health registries is the lack of records for the disease of interest before the earliest date of data availability. A patient who appears to be an incident patient in a given year, may have received the diagnosis before the registry started to capture data. Such misclassification of prevalent as incident cases leads to overestimation of incidence early in the observation period. This problem is sometimes labeled lookback bias or washout bias.\n",
        "\n",
        "\n",
        "### Lookahead bias\n",
        "The wash-out challenge interacts with another issue which may be labelled the lookahead problem. In order to avoid errors, studies of incidence based on health registry data sometimes require patients to have at least two or more registered events with the diagnostic code before classifying patients as having a given disease. This requirement creates a problem because patients towards the end of the observation period have had less time to accumulate multiple events and as a result there is an underestimation of incidence. \n",
        "\n",
        "\n",
        "### Consequence: Misleading estimate of trend\n",
        "Taken together the underestimation of incidence in the beginning of the time period due to wash-out bias, and an underestimation towards the end caused by look-ahead bias, may create a false impressison that there is a declining trend in the incidence for the disease when the trend may be stable or even increasing. \n",
        "\n",
        "### Solution\n",
        "One soution would be to examine the importance of lookback and lookahead using within the available data and to find a function that describes the relationship between the length of the lookback/lookahed time period and how it affects incidence. This function can be used to estimate what the incidence would be with longer lookback/lookahead periods.\n",
        "\n",
        "More specifically, the method uses the observed dataset to estimate a non-linear function indicating the degree to which patients will remain incidence patients as more data is added before and after a given year. Based on the regression results, we calculated bias-adjusted incidences i.e. the incidence one would expect with a very long observation-period. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9xjHqpaFAk2"
      },
      "source": [
        "## Overview of functions\n",
        "To perform the calculations, the following functions are useful:\n",
        "- *select_rows()*\n",
        "  - Select only the relevant rows i.e. those with the diganostic code that is relevant for the disease \n",
        "  - Useful if the dataframe consists of events with codes that are irrelevant for the disease you want to estimate\n",
        "\n",
        "- *raw_incidence()* \n",
        "  - Counts the number of new cases each year that have no previous events in the database\n",
        "  - Used as a benchmark - compare it with the adjusted results\n",
        "\n",
        "- *lookback_pattern()*\n",
        "  - The number (or percent) of new cases in a given year that remain new cases as the length of the look-back period is gradually increased\n",
        "  - Used as datapoints to identify the underlying curve \n",
        "\n",
        "- *fit_curve()*  \n",
        "  - Estimates the coefficient in a (possibly non-linear) function that gives the best fit to the pattern in the data\n",
        "  - Uses the data produced by the _lookback_pattern()_ function (and the _single_pattern()_ function)\n",
        "  - Implemented using scipy _optimize_ algorithm (Thank you, scipy team!)\n",
        "\n",
        "- *single_pattern()*\n",
        "  - The share of all patients in a year that are single event patients (with only one relevant registered event) and that remain single when more data is gradually added before and after the year in question\n",
        "  - Used to adjust for lookahead bias when two events are required since it allows us to estimate how many cases one expects to be truly single (meaning and the rest will have two events)\n",
        "\n",
        "- *adjusted_incidence()*\n",
        "  - The number of new cases each year after adjusting for lookback and lookahead\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQZgCBnKYhTY"
      },
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import optimize\n",
        "from datetime import datetime, timedelta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOzWgI00aXFO"
      },
      "source": [
        "def select_rows(df, codes, cols):\n",
        "  \"\"\"\n",
        "  Marks all rows in a dafaframe that have the code(s) in one or some it is column(s)\n",
        "\n",
        "  Args:\n",
        "    df (dataframe): the dataframe with the codes and the columns\n",
        "    codes (string or list of str): the codes to be marked\n",
        "    cols (str or list of str): the colum(s) where the codes are\n",
        "  \n",
        "  Returns:\n",
        "    A boolean series\n",
        "  \n",
        "  Note:\n",
        "    Missing value is here the same as False (no code is found)\n",
        "    The columns can have be single valued (with only one code in each cell) or have multiple values in each cell (one column only)\n",
        "  \"\"\"\n",
        "    if not isinstance(codes, list):\n",
        "        codes=[codes]\n",
        "    \n",
        "    # multiple columns with code(s)\n",
        "    if isinstance(cols, list):\n",
        "      rows=df[cols].isin(codes).any(axis=1)\n",
        "    \n",
        "    # one column with code(s)\n",
        "    else:\n",
        "        codes='|'.join(codes)\n",
        "        rows=df[cols].str.contains(codes, na=False)\n",
        "    return rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZgu5grlcwEg"
      },
      "source": [
        "def raw_incidence(df, codes=None, cols=None, pid='pid', date='date', \n",
        "                  required_events=1):\n",
        "  \"\"\"\n",
        "  Counts the number of new cases each year i.e. persons that have no previous events in the dataframe\n",
        "\n",
        "  Args:\n",
        "    df: dataframe with information about individual level events\n",
        "    codes (string or list of str): the codes for the disease you want to count\n",
        "    cols (str or list of str): the colum(s) where the codes are\n",
        "    pid (str): the personal identifier used in the dataframe\n",
        "    date (str): the column with the dates of the events\n",
        "    required_events (int): the number of events required before a case is counted as having the disease\n",
        "  \n",
        "  Returns: \n",
        "    Series with the number of new cases for each year available in the dataframe\n",
        "  \"\"\"\n",
        "    # if no codes are specified, all observations are relevant \n",
        "    # (when the dataframe already has only relevant observations)\n",
        "    if codes:\n",
        "        rows=select_rows(df=df, codes=codes, cols=cols, pid=pid)\n",
        "        df=df[rows]    \n",
        "              \n",
        "    # identify first event\n",
        "    first_event=df.groupby(pid)[date].min()\n",
        " \n",
        "    if required_events>1:\n",
        "        events=df.groupby(pid).size()\n",
        "        enough_events = events>=required_events\n",
        "        first_event=first_event[enough_events]\n",
        "        \n",
        "    # unadjusted incidence (number of cases)\n",
        "    raw_incidence=first_event.dt.year.value_counts().sort_index()\n",
        "    raw_incidence.index=raw_incidence.index.astype(int)\n",
        "        \n",
        "    return raw_incidence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_DNktiRdwqW"
      },
      "source": [
        "  def lookback_pattern(df, codes=None, cols=None, pid='pid', date='date', \n",
        "            year=None, step=200, pct=False):\n",
        "    \"\"\"\n",
        "    The number (or percent) of new cases in a given year that remain new cases as the length of the look-back period is gradually increased.\n",
        "    \n",
        "    Args:\n",
        "      df: dataframe with information about individual level events\n",
        "      codes (string or list of str): the codes for the disease you want to count\n",
        "      cols (str or list of str): the colum(s) where the codes are\n",
        "      pid (str): the personal identifier used in the dataframe\n",
        "      year (None, int, or list of int): The year for which you want incidence estimates. Default is None which calculates the incidence for all possible years\n",
        "      step (int): The stepwise increase in the look-back period (measured in days) used when creating the historical pattern between the size of the lookback period and the share of incidence patients in a year that remain incidence patients as more historical data is added \n",
        "      pct (bool, default: False): If True, the function will return an estimate of the patients\n",
        "\n",
        "  Example:\n",
        "      w=lookback_pattern(df=df, codes='K50', cols='icd', step=100, pct=True) \n",
        "    \"\"\"\n",
        "    # if no codes are specified, all observations are relevant \n",
        "    # (when the dataframe already has only relevant observations)\n",
        "    if codes:\n",
        "        rows=select_rows(df=df, codes=codes, cols=cols, pid=pid)\n",
        "        df=df[rows]\n",
        "    \n",
        "    if (year is None) or isinstance(year,list):\n",
        "        still_left=_lookback_years(df=df, codes=None, cols=None, pid=pid, \n",
        "                                   date=date, year=year, step=step, \n",
        "                                   required_events=required_events, pct=pct)\n",
        "        return still_left\n",
        "    \n",
        "    patient_pids=set(df.loc[df[date].dt.year==year, pid].unique())\n",
        "    n_patients=len(patient_pids)\n",
        "    \n",
        "    historical_df=df[(df.pid.isin(patient_pids)) & (df[date].dt.year<year)]\n",
        "\n",
        "    start_date=pd.to_datetime(f'01-01-{year}')\n",
        "    min_date=df[date].min()\n",
        "    range_days=(start_date-min_date).days\n",
        "    \n",
        "    historical_df['days_from_start']=(start_date-historical_df[date]).dt.days\n",
        "        \n",
        "    if pct:\n",
        "        still_first={0:1.0}  \n",
        "    else:\n",
        "        still_first={0:n_patients}  \n",
        "        \n",
        "    for days in range(step,range_days,step):\n",
        "        washout_rows=historical_df.days_from_start<days\n",
        "        washout_pids=set(historical_df.loc[washout_rows,pid].unique())\n",
        "        with_previous_events_pids=patient_pids.intersection(washout_pids)\n",
        "        n_with_previous_events= len(with_previous_events_pids)\n",
        "        n_no_previous_history= n_patients - n_with_previous_events\n",
        "        if pct:\n",
        "            still_first[days]= n_no_previous_history/n_patients\n",
        "        else:\n",
        "            still_first[days]= n_no_previous_history\n",
        "    return pd.Series(still_first)\n",
        "\n",
        "def _lookback_years(df, codes, cols, pid='pid', date='date', \n",
        "                   year=None, step=200, required_events=1, pct=False):\n",
        "  \"\"\"\n",
        "  Helper function used when multiple years is used in lookback_pattern()\n",
        "  \"\"\"\n",
        "    if year is None:\n",
        "        min_year=df[date].min().year\n",
        "        years=sorted(df.loc[df.date.dt.year>min_year, date].dt.year.unique())\n",
        "    else:\n",
        "        years=year\n",
        "        \n",
        "    still_left={}\n",
        "    for year in years:\n",
        "        still_left[year]=lookback_pattern(df=df, codes=codes, cols=cols, pid=pid, \n",
        "                                 date=date, year=year, step=step, \n",
        "                                 required_events=required_events, pct=pct)\n",
        "    return pd.DataFrame(still_left)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_cNbQ3mgazY"
      },
      "source": [
        "def single_pattern(df, codes=None, cols=None, pid='pid', date='date', \n",
        "            year=None, step=0, required_events=1, pct=False):\n",
        "  \"\"\"\n",
        "    The percent unique patients in a given year that remain unique when more data is gradually added before and after the year in question\n",
        "    \n",
        "    Args:\n",
        "      df: dataframe with information about individual level events\n",
        "      codes (string or list of str): the codes for the disease you want to count\n",
        "      cols (str or list of str): the colum(s) where the codes are\n",
        "      pid (str): the personal identifier used in the dataframe\n",
        "      year (None, int, or list of int): The year for which you want incidence estimates. Default is None which calculates the incidence for all possible years\n",
        "      step (int): The stepwise increase by which the observed time-period is increased (both before and after the given year).     \n",
        "      pct (bool, default: False): If True, the function will return an estimate of the patients\n",
        "  \n",
        "  Example:\n",
        "    s=singles(df=df, codes='K50', cols='icd', date='date',step=100,pct=True)         \n",
        "\n",
        "  Note:\n",
        "    If the data available before/after the given year is not of equal length, the algorithm will keed adding data in steps until it hits the end of the data at one end - and then stop.\n",
        "\n",
        "  \"\"\"\n",
        "    # if no codes are specified, all observations are relevant \n",
        "    # (when the dataframe already has only relevant observations)\n",
        "    if codes:\n",
        "        rows=select_rows(df=df, codes=codes, cols=cols, pid=pid)\n",
        "        df=df[rows]\n",
        "    \n",
        "    if (year is None) or isinstance(year,list):\n",
        "        still_single=_single_years(df=df, codes=codes, cols=cols, pid=pid, date=date, year=year, step=step, required_events=required_events, pct=pct)\n",
        "        return still_single\n",
        "    include = (df[date].dt.year==year)\n",
        "    single_rows = df[include].groupby(pid).size()<=required_events\n",
        "    original_single_pids = set(single_rows.index[single_rows==1])\n",
        "    \n",
        "    n_patients=df.loc[include, pid].nunique()\n",
        "    min_date=df.date.min()\n",
        "    max_date=df.date.max()\n",
        "    \n",
        "    date_range=(max_date-min_date).days\n",
        "    still_single={}\n",
        "    for expand_days in range(0,date_range,step):\n",
        "        start_date = datetime(year=year, month=1, day=1) - timedelta(days=expand_days)\n",
        "        end_date = datetime(year=year, month=12, day=31) + timedelta(days=expand_days)\n",
        "        if (start_date<min_date) or (end_date>max_date):\n",
        "            break\n",
        "        larger_sample = (start_date < df[date]) & (df[date] < end_date)\n",
        "        \n",
        "        single_rows = df[larger_sample].groupby(pid).size()<=required_events\n",
        "        new_single_pids = set(single_rows.index[single_rows==1])\n",
        "        \n",
        "        still_single_pids = original_single_pids & new_single_pids\n",
        "        if pct:\n",
        "            still_single[expand_days] = len(still_single_pids)/n_patients\n",
        "        else:\n",
        "            still_single[expand_days] = len(still_single_pids)\n",
        "    \n",
        "    return pd.Series(still_single, dtype='float64')\n",
        "\n",
        "def _single_years(df, codes, cols, pid='pid', date='date', year=None, step=200, required_events=1, pct=False):\n",
        "    \"\"\"\n",
        "    Helper function used when multiple years is used in single_pattern()\n",
        "    \"\"\"\n",
        "    if year is None:\n",
        "        min_year=df[date].min().year\n",
        "        years=sorted(df.loc[df.date.dt.year>min_year, date].dt.year.unique())\n",
        "    else:\n",
        "        years=year\n",
        "        \n",
        "    still_single={}\n",
        "    for year in years:\n",
        "        still_single[year]=single_pattern(df=df, codes=codes, cols=cols, pid=pid, date=date, year=year, step=step, required_events=required_events, pct=pct)\n",
        "    return pd.DataFrame(still_single)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktk6GYa4ggVX"
      },
      "source": [
        "def fit_curve(df, pred=True, func=False):\n",
        "  \"\"\"\n",
        "  Estimates the coefficient in a function that gives the best fit to the pattern in the data\n",
        "  \n",
        "  Args:\n",
        "    df (dataframe): a dataframe with the data for the pattern that will be fitted\n",
        "    pred (bool): Will print the predicted values if True\n",
        "    func (function): a user defined function that defines the curve. If False, default is a hyperbolic curve: a + (b/(1+c*x))\n",
        "\n",
        "  Returns (array): A list of the estimated parameters\n",
        "    \n",
        "  \"\"\"\n",
        "  if not func:\n",
        "    def func(x, a, b, c):\n",
        "      return  a + (b/(1+c*x))\n",
        "\n",
        "  df=df.stack().reset_index()\n",
        "  df.columns=['x', 'year', 'y']\n",
        "  #does not make sense to have zero history added so it messes up results to include it\n",
        "  df=df[df['x']!=0]\n",
        "  coeff, pcov = optimize.curve_fit(func, df.x.to_numpy(), df.y.to_numpy())\n",
        "  pred_y = [func(x, *coeff) for x in range(0,2000,100) ]\n",
        "  if pred:\n",
        "    print(pred_y)\n",
        "  # consider returing covariances as well? (pcov)\n",
        "  return coeff\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq0vMb0vgv9B"
      },
      "source": [
        "def adjusted_incidence(df, codes=None, cols=None, pid='pid', date='date', required_events=1, start_year=None, \n",
        "            year=None, step=0, lookback_func=False, single_func=False):\n",
        "    # if no codes are specified, all observations are counted as relevant for the incidence\n",
        "    \"\"\"\n",
        "    The number of new cases each year after adjusting for lookback and lookahead  \n",
        "\n",
        "    Args:\n",
        "      df: dataframe with information about individual level events\n",
        "      codes (string or list of str): the codes for the disease you want to count\n",
        "      cols (str or list of str): the colum(s) where the codes are\n",
        "      pid (str): the personal identifier used in the dataframe\n",
        "      year (None, int, or list of int): The year for which you want incidence estimates. Default is None which calculates the incidence for all possible years\n",
        "      step (int): The stepwise increase in the look-back period (measured in days) used when creating the historical pattern between the size of the lookback period and the share of incidence patients in a year that remain incidence patients as more historical data is added \n",
        "      start_year (int): the first year for which you will provide incidence estimates\n",
        "      lookback_func (func): the function that describes the lookback pattern as more data is added (default is hyperbolic)\n",
        "      single_func (func): the function that describes the pattern of unique cases as more data is added (default is hyperbolic)\n",
        "\n",
        "    Returns:\n",
        "      A Series with estimates of the number of new cases each year after adjusting for lookback and lookforward based on the trends in the observed data \n",
        "    \n",
        "    Example:\n",
        "      n=adjusted_incidence(df=df, codes='K50', cols='icd', date='date',step=50, start_year=2008)\n",
        "\n",
        "    Note:\n",
        "      If user supplied functions are used the first coefficient must be the limit of the curves (constant)         \n",
        "\n",
        "    \"\"\"\n",
        "     \n",
        "    if codes:\n",
        "        rows=select_rows(df=df, codes=codes, cols=cols, pid=pid)\n",
        "        df=df[rows]    \n",
        "\n",
        "    #adjust for washout\n",
        "    raw=raw_incidence(df=df, date=date)  \n",
        "    \n",
        "    washout_pattern=lookback_pattern(df=df, step=step, pct=True)\n",
        "\n",
        "    if not lookback_func:\n",
        "      def lookback_func(x, a, b, c):\n",
        "          return  a + (b/(1+c*x))         \n",
        "    \n",
        "    washout_curve=fit_curve(df=washout_pattern, func=lookback_func)\n",
        "    \n",
        "    # start from first year of data with one year of lookback\n",
        "    lookback_days=(raw.index-start_year)*365    \n",
        "    pred_y = [func(x, *washout_curve) for x in lookback_days ]\n",
        "    adjustment_factor = washout_curve[0]/pred_y\n",
        "    adjusted_for_washout = raw * adjustment_factor\n",
        "    \n",
        "    adjusted_incidence = adjusted_for_washout\n",
        "    \n",
        "    # forward bias\n",
        "    if required_events==2:\n",
        "\n",
        "      df['__year']=df[date].dt.year\n",
        "      \n",
        "      n_patients=df.groupby('__year').pid.nunique()\n",
        "      \n",
        "      forward=single_pattern(df=df, step=step, pct=True)         \n",
        "      \n",
        "      if not single_func:\n",
        "        def single_func(x, a, b, c):\n",
        "            return  a + (b/(1+c*x))\n",
        "      single_curve=fit_curve(df=forward, func=single_func)\n",
        "      n_true_singles=n_patients*single_curve[0]\n",
        "      \n",
        "      adjusted_incidence=adjusted_for_washout-n_true_singles\n",
        "    elif required_events>2:\n",
        "      print('Adjustment when more than 2 events is required is not yet implemented')\n",
        "      adjusted_incidence=None\n",
        "    return adjusted_incidence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87MyIs5IYyio"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd6ifA6-Yx2n"
      },
      "source": [
        ""
      ]
    }
  ]
}