{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "importing from multiple files",
      "provenance": [],
      "authorship_tag": "ABX9TyN0+8Lm+uzfShFDdwj0/F3w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmelberg/health-analytics-using-python/blob/master/importing_from_multiple_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY3GnIxI1dN2"
      },
      "source": [
        "# Importing from multiple files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acdwgy4h1jOD"
      },
      "source": [
        "Sometimes health data arrives in muplie files, for instance one file for each year. Our task is to extract information across the different files. For instance, to extract all events and information about persons who at one point have received a diabetes diagnosis in one of the files.\n",
        "\n",
        "To make things even more difficult, sometimes these files may have different headlines or different systems for coding variables. For instance, the categories for etnicity or gender may have been expanded in recent years, which means that we must recategorize data of previous years for data to be comparable and aggregated in one file. And to top it off, the data-types for similar variables may - for reasons only known to my enemies - randomly change datatypes. Integers may be stored as floats and so on. \n",
        "\n",
        "These problems may often cause a lot of time consuming munging, and it would be useful to have some functions that could make it easier. This notebook will create tools to help with this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1P0GrvY1jI3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OuTAwAS1jGT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBxVO-IQ1jBV"
      },
      "source": [
        "# imports\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pickle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeLNm09o4Z3_"
      },
      "source": [
        "#%% helper functions\n",
        "def _tolist(string_or_list):\n",
        "  \"\"\"\n",
        "  returns a list\n",
        "\n",
        "    string becomes a list of one object\n",
        "    tuple becomes a list\n",
        "    list remains a list\n",
        "    \"\"\"\n",
        "    if isinstance(string_or_list, list):\n",
        "        return string_or_list\n",
        "    else:\n",
        "        return [string_or_list]\n",
        "    \n",
        "def _invert(schema):\n",
        "  \"\"\"\n",
        "  a \n",
        "  \"\"\"\n",
        "    inverted = dict( (v,k) for k in schema \n",
        "                       for v in schema[k] )\n",
        "    return inverted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXCteg7j4GJp"
      },
      "source": [
        "\n",
        "def _totuple(str_or_list):\n",
        "    \"\"\"\n",
        "    converts a string or a list into a tuple\n",
        "        tuplify('npr20')\n",
        "        tuplify(['results', 'resultater'])\n",
        "        \n",
        "    note: may seems unnecessary, but it is suprisingly helpful\n",
        "        allows input to be single str or list and then changed\n",
        "    \"\"\"\n",
        "    \n",
        "    if type(str_or_list) == str:\n",
        "        result = tuple([str_or_list])\n",
        "    if type(str_or_list) == list:\n",
        "        result = tuple(str_or_list)\n",
        "    return result\n",
        "\n",
        "def _check_if_path(path):\n",
        "    \"\"\" gets the current path if no path is specified and \n",
        "        makes a list of it if only one path is specified\"\"\"\n",
        "\n",
        "    if not path:\n",
        "        path = [os.getcwd()]\n",
        "    if type(path) == str:\n",
        "        path = [path]\n",
        "\n",
        "    if not path[0].endswith('/'):\n",
        "        path = [path[0] +'/']        \n",
        "    return path\n",
        "#%%\n",
        "def extract_filename(file, ignore_path=True, ignore_format=True):\n",
        "    \"\"\" Extracts filename from a string\n",
        "        \n",
        "    >>> extract_filename('C:/dat/meps/annual/meps2014.csv')\n",
        "    meps2004\n",
        "    \"\"\"\n",
        "    tmp = file    \n",
        "    if ignore_path:\n",
        "        tmp = file.split('/')[-1]\n",
        "    if ignore_format:\n",
        "        tmp = tmp.split('.')[0]\n",
        "    return tmp\n",
        "\n",
        "#%%\n",
        "def get_vars(files=None):\n",
        "    \"\"\"\n",
        "    returns the variable names in a file or list of files\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    \n",
        "    files    : str or list\n",
        "        filename or list of filenames\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "    \n",
        "    A dictionary with the filenames as keys and the column names as values\n",
        "    \"\"\"\n",
        "    \n",
        "    files=_tolist(files)        \n",
        "    variables = {}\n",
        "\n",
        "    for i, file in enumerate(files):\n",
        "        tmp = pd.read_csv(file, nrows = 5, header = 0) \n",
        "        variables[file] = tmp.columns.tolist()\n",
        "    return variables\n",
        "\n",
        "def get_dtypes(files=None):\n",
        "    files=_tolist(files)\n",
        "    datatypes = {}\n",
        "    for i, file in enumerate(files):\n",
        "        tmp = pd.read_csv(file, nrows = 5, header = 0) \n",
        "        #variables[file] = tmp.columns.tolist()\n",
        "        datatypes[file] = tmp.dtypes.tolist()\n",
        "    return datatypes\n",
        "\n",
        "def get_nfirst(files=None, n=5):\n",
        "    files=_tolist(files)\n",
        "    nfirst = {}\n",
        "    for i, file in enumerate(files):\n",
        "        nfirst[file] = pd.read_csv(file, nrows=n, header=0)\n",
        "    return nfirst\n",
        "\n",
        "# Rewrite this (Very inefficient and may cause errors if n is larger than rows in file)        \n",
        "def get_nlast(files=None, n=5):\n",
        "    files=_tolist(files)\n",
        "    nlast={}\n",
        "    for i, file in enumerate(files):\n",
        "        tmp = pd.read_csv(file, header=0) #what if no header\n",
        "        nlast[file] = tmp.tail(5)\n",
        "    return nlast\n",
        "\n",
        "#%%\n",
        "def explore(files=None, rows=5):\n",
        "    files=_tolist(files)\n",
        "    nfirst = {}\n",
        "    variables = {}\n",
        "    datatypes = {}\n",
        "    for i, file in enumerate(files):\n",
        "        nfirst[file] = pd.read_csv(file, nrows=rows, header=0)\n",
        "        variables[file] = nfirst[file].columns.tolist()\n",
        "        datatypes[file] = nfirst[file].dtypes.tolist()\n",
        "    return nfirst, variables, datatypes\n",
        "\n",
        "\n",
        "\n",
        "#%%\n",
        "def get_filelist(path=None, \n",
        "                 starts_with=None, \n",
        "                 ends_with=None, \n",
        "                 contains=None, \n",
        "                 subpaths=False, \n",
        "                 strip_folders=False, \n",
        "                 strip_file_formats=False,\n",
        "                 regexp=None, \n",
        "                 only_filename=False):\n",
        "    \n",
        "    \"\"\" \n",
        "    Returns a list of files  \n",
        "    \n",
        "    \n",
        "    parameters\n",
        "    ----------\n",
        "        path (str or list) : the directory to search (str) \n",
        "                             or a list of directories to search\n",
        "        starts_with (str or list): only includes files that starts with a\n",
        "            given string (or list of strings). Default: None.\n",
        "            \n",
        "        ends_with (str or list): only includes files that ends with a\n",
        "            given string (or list of strings). Default: None.\n",
        "            \n",
        "            \n",
        "        ends_with (str or list): only includes files that ends with a\n",
        "            given string (or list of strings). Default: None.\n",
        "            \n",
        "        contains (str or list): only includes files that contains a\n",
        "            given string (or list of strings). Default: None.\n",
        "        \n",
        "        subpaths (bool) : Includes all subdirectories if True. Dafault: False\n",
        "    \n",
        "        example\n",
        "        -------\n",
        "        files = get_filelist(path = 'C:/dat/meps/annual/', starts_with='meps', ends_with='csv')\n",
        "    \"\"\"\n",
        "    \n",
        "    # Note: may be extended to include list of paths, and/or all subpaths\n",
        "    \n",
        "    path = _check_if_path(path)\n",
        "    all_files = []\n",
        "\n",
        "    for folder in path:\n",
        "        # include subdirectories if subpaths is True            \n",
        "        if subpaths: \n",
        "            files = [x[0] for x in os.walk(folder)]\n",
        "        else:\n",
        "            files = os.listdir(folder)\n",
        "        \n",
        "        # include only files that satisfy given criteria\n",
        "        files = select_from_filelist(files=files, \n",
        "                             starts_with=starts_with, \n",
        "                             ends_with=ends_with, \n",
        "                             contains=contains, \n",
        "                             regexp=regexp, \n",
        "                             only_filename=only_filename)\n",
        "        \n",
        "        # make list of all files\n",
        "        full_files = [folder+file for file in files]\n",
        "        \n",
        "        all_files.append(full_files)\n",
        "        \n",
        "    return all_files[0] #check if this works with multiple dirs\n",
        "    \n",
        "#%%\n",
        "def select_from_list(lst, \n",
        "                 starts_with=None, \n",
        "                 ends_with=None, \n",
        "                 contains=None, \n",
        "                 regexp=None):\n",
        "    \"\"\"\n",
        "    Selects some elements from a list of strings\n",
        "    \n",
        "    Example\n",
        "    In a list of many many meps files for several years, get only files\n",
        "    from year 2000:\n",
        "        \n",
        "    >>>files = select_from_list(files, starts_with=\"meps20\", only_filename=True)\n",
        "    >>>k73x = select_from_list(icdtopid.keys, starts_with='K73')\n",
        "    \n",
        "    \"\"\"\n",
        "    # hmm not happy with this ... not clear if it is and or or when multiple conditions are specified\n",
        "    \n",
        "   \n",
        "    if starts_with:\n",
        "        selected = [element for element in lst if element.startswith(starts_with)]\n",
        "    \n",
        "    if ends_with:\n",
        "        selected = [element for element in lst if element.endswith(ends_with)]\n",
        "        \n",
        "    if contains:\n",
        "        selected = [element for element in lst if contains in element]\n",
        "        \n",
        "    if regexp:\n",
        "        regxpr=re.complie(regexpr)\n",
        "        selected = [element for element in lst if regxpr.search(element) is not None]  \n",
        "           \n",
        "    return selected\n",
        "\n",
        "#%%\n",
        "def select_from_filelist(files, \n",
        "                 starts_with=None, \n",
        "                 ends_with=None, \n",
        "                 contains=None, \n",
        "                 regexp=None, \n",
        "                 ignore_path=True, \n",
        "                 ignore_format=True,\n",
        "                 only_filename=True):\n",
        "    \"\"\"\n",
        "    Selects some elements from a list of strings\n",
        "    \n",
        "    Example\n",
        "    In a list of many many meps files for several years, get only files\n",
        "    from year 2000:\n",
        "        \n",
        "    >>>files = select_from_list(files, starts_with=\"meps20\", only_filename=True)\n",
        "    >>>k73x = select_from_list(icdtopid.keys, starts_with='K73')\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    for file in files:\n",
        "        if starts_with:\n",
        "            beginnings = _totuple(starts_with)\n",
        "            files = [file for file in files \n",
        "                     if extract_filename(file=file).startswith(beginnings)]\n",
        "        if ends_with:\n",
        "            endings = _totuple(ends_with)\n",
        "            files = [file for file in files if file.endswith(endings)]\n",
        "        if contains:\n",
        "            files = [file for file in files if contains in file]\n",
        "        if regexp:\n",
        "            regxpr=re.complie(regexp)\n",
        "            files = [file for file in files if regxpr.search(file) is not None]             \n",
        "    return files\n",
        "      \n",
        "\n",
        "#%%\n",
        "def ids_from_csv(files,\n",
        "                 find,\n",
        "                 col_info = {'single': ['icdmain'], 'multi': ['icdbi']},\n",
        "                 id_col='pid',\n",
        "                 schema={'pid': ['pid']},\n",
        "                 query=None, \n",
        "                 dtype=None,\n",
        "                 union=False,\n",
        "                 **kwargs):\n",
        "    \"\"\"\n",
        "    Get set of ids from rows that satisfy some conditions in a list of csv files\n",
        "            \n",
        "    Parameters\n",
        "    ----------\n",
        "        files: (list) List of files to include\n",
        "        \n",
        "        id_col: (string) Column name containing the ids\n",
        "        \n",
        "        schema: (dictionary) \n",
        "            A mapping of desired column names (keys) to the equivalent and \n",
        "            possible diverse column names in the various files. \n",
        "            Example: The columns with id and year information may have \n",
        "            different names in different files and we want to label \n",
        "            all the id columns \"pid\" and similarly for 'year':\n",
        "                \n",
        "                schema={'pid'  : ['id', 'ID', 'person'], \n",
        "                        'year' : ['jahre', 'year', 'yyyy']}\n",
        "                \n",
        "        find: (dictionary) \n",
        "            Key is column name to search, \n",
        "            Value is list of strings to search for\n",
        "            \n",
        "            Example: find = {'icd_main': ['K50, K51']}\n",
        "        \n",
        "        query: (string) \n",
        "            Text specifying a query. \n",
        "            Example: query = \"age > 18\"\n",
        "            \n",
        "        union: (bool, default: False)\n",
        "            If True, returns a single set of the union of all ids\n",
        "        \n",
        "                                      \n",
        "    Example\n",
        "    -------\n",
        "    Get ids for indidiuals who have K50 or K51 in the column icd_main:\n",
        "    \n",
        "    >>>ibd_codes = {'icd_main': ['K50, K51']}       \n",
        "    >>>ids_from_csv(df, id_col='pid' find=ibd_codes)\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "        dictionary with files as keys and a set of ids as values\n",
        "    \"\"\"\n",
        "    \n",
        "    old_to_new = _invert(schema)\n",
        "    #original_cols= old_to_new.keys()\n",
        "    \n",
        "    oldvars = {var for varlist in schema.values() for var in varlist}\n",
        "    \n",
        "    files=_tolist(files)\n",
        "    ids={}\n",
        "    \n",
        "    for file in files:\n",
        "        print(file)\n",
        "        header = pd.read_csv(file, nrows=0)\n",
        "        header = set(header.columns)\n",
        "        usecols = header.intersection(oldvars)\n",
        "        df = pd.read_csv(file, usecols=usecols, dtype=dtype)\n",
        "        df = df.rename(columns=old_to_new)                     \n",
        "        idset = ids_from_df(df=df, id_col=id_col, find=find, query=query, **kwargs)\n",
        "        ids[file] = idset   \n",
        "    \n",
        "    if union:\n",
        "        ids = set.union(*ids.values())\n",
        "        #alternatively a dict with all the same values for the filekeys\n",
        "        \n",
        "    return ids\n",
        "#%%\n",
        "\n",
        "def ids_from_df(df, id_col='pid', find=None, query=None, **kwargs):\n",
        "    \"\"\"\n",
        "        Gets the ids that satisfy some conditions\n",
        "                \n",
        "        Parameters\n",
        "        ----------\n",
        "            df: (dataframe) Dataframe\n",
        "            id_col: (string) name of column with the ids\n",
        "            find: (dictionary) Key is column name to search, value is list of strings to search for\n",
        "            query: (string) String specifying a selection query. Example: \"year > 2003\"\n",
        "            out: (string, 'set') Format to return the ids\n",
        "            \n",
        "        Example\n",
        "        -------\n",
        "        Get all ids for peole who have K50 or K51 in the column icd_main:\n",
        "        \n",
        "        >>>find = {'icd_main': ['K50, K51']}       \n",
        "        >>>ids_from_df(df, id_col='pid', find=None, query=None, out='set', **kwargs)\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "            Set\n",
        "    \"\"\"\n",
        "    \n",
        "    if query:\n",
        "        df = df.query(query)\n",
        "        \n",
        "    if find:\n",
        "        #boolean array, staring point: all false, no rows are included\n",
        "        combined=np.array([False] * len(df))\n",
        "        \n",
        "        for var, searchlist in find.items():\n",
        "            searchstr = \"|\".join(searchlist)\n",
        "            true_if_found = df[var].str.contains(searchstr, na=False)\n",
        "            combined = np.logical_or(combined, np.array(true_if_found))\n",
        "        df=df[combined]\n",
        "        #potentially better way if we know single item columns\n",
        "        #not finished code\n",
        "#        if col_regex=True:\n",
        "#                sing_item_cols = df.filter(regex=col_regex, axis=1)\n",
        "#        mask = df[sing_item_cols].isin(searchlist)\n",
        "#        true_if_found = mask.any\n",
        "#        \n",
        "    ids = set(df[id_col])\n",
        "         \n",
        "    return ids\n",
        "\n",
        "#%%\n",
        "def read_csv_using_ids(files, \n",
        "                 ids, \n",
        "                 schema=None, \n",
        "                 id_col='pid', \n",
        "                 columns=None, \n",
        "                 select=None, \n",
        "                 dtype=None, \n",
        "                 **kwargs):\n",
        "    \"\"\"\n",
        "    Aggregate selected rows and columns from a list of csv files to a single dataframe\n",
        "    files: list\n",
        "        list of csv files to read\n",
        "        \n",
        "    ids: set or dict\n",
        "        if set: use same set of ids to read all files\n",
        "        if dict: key is file, values is set of ids to include for the file\n",
        "           \n",
        "    schema : dict (with lists of columns as values)\n",
        "        keys are the desired column names that corresponod to the list of columns names in values\n",
        "        example: \n",
        "            A schema to so specify that files named 'person' 'number' and 'id' in the different csv files contain the same information and should be labelled 'pid:\n",
        "            {'pid' : ['person', number', 'id']}\n",
        "                    \n",
        "    id_col: str (default is 'pid')\n",
        "        the column name that containts information about id (column names from the schema)\n",
        "        \n",
        "    columns: List\n",
        "        the columns in the files to be read (column names from the schema)\n",
        "  \n",
        "    select: string\n",
        "        additional query to limit the result\n",
        "        example: query='female==1'\n",
        "         \n",
        "    dtype:dictionary of dtypes (column names from the schema)\n",
        "        speficy the dtypes of the columns\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    files=_tolist(files)\n",
        "    dfs=[]\n",
        "        \n",
        "    if schema:\n",
        "        oldvars = {var for varlist in schema.values() for var in varlist}\n",
        "        old_to_new = dict( (v,k) for k in schema for v in schema[k] )\n",
        "        \n",
        "    for file in files:\n",
        "        print(file)\n",
        "        header = pd.read_csv(file, nrows=0, encoding='latin-1')\n",
        "        header = set(header.columns)\n",
        "        \n",
        "        # is columns are specified, use this, if not, use all columns \n",
        "        if columns:        \n",
        "            oldvars = {var for k, varlist in schema.items() \n",
        "                        if k in columns \n",
        "                        for var in varlist} \n",
        "            \n",
        "            use_columns = header.intersection(oldvars)\n",
        "        else:\n",
        "            use_columns = header\n",
        "        \n",
        "        df = pd.read_csv(file, usecols=use_columns, encoding='latin-1')\n",
        "        \n",
        "        if schema:\n",
        "            df = df.rename(columns=old_to_new)\n",
        "        \n",
        "        # allow user to input a single id set/list that applies to all files\n",
        "        if (isinstance(ids, set)) or (isinstance(ids, list)):\n",
        "            df = df[df[id_col].isin(ids)]\n",
        "        else:\n",
        "            df = df[df[id_col].isin(ids[file])]\n",
        "     \n",
        "        if select:\n",
        "            df = df.query(select)\n",
        "        dfs.append(df)\n",
        "    dfs=pd.concat(dfs)\n",
        "    return dfs\n",
        "\n",
        "#%%\n",
        "\n",
        "def read_hdf_using_ids(file_keys,\n",
        "                 ids, \n",
        "                 schema=None, \n",
        "                 id_col='pid', \n",
        "                 columns=None, \n",
        "                 select=None, \n",
        "                 dtype=None, \n",
        "                 **kwargs):\n",
        "    \"\"\"\n",
        "    Aggregate selected rows and columns from a tables in a hdf datastore to a single dataframe\n",
        "    path: dict\n",
        "        a dictionary of paths with a list of keys for the files to be read\n",
        "        example:  \n",
        "            path_keys = {'Q:/mepsdata/annual/hdf/meps.h5' :['meps1992', 'meps1993']}\n",
        "        \n",
        "    ids: dict\n",
        "        a dict with the ids of the rows to be included in each file\n",
        "        the key in the dictionary is a tuple with path and key to the table\n",
        "        example: ids = {('Q:/mepsdata/annual/hdf/meps.h5', 'meps1992'): [28, 35]}\n",
        "           \n",
        "    schema : dict (with lists of columns as values)\n",
        "        keys are the desired column names that corresponod to the list of columns names in values\n",
        "        example: \n",
        "            A schema to so specify that files named 'person' 'number' and 'id' in the different csv files contain the same information and should be labelled 'pid:\n",
        "            {'pid' : ['person', number', 'id']}\n",
        "                    \n",
        "    id_col= str (default is 'pid')\n",
        "        the column name that containts information about id (column names from the schema)\n",
        "        \n",
        "    columns= List\n",
        "        the columns in the files to be read (column names from the schema)\n",
        "  \n",
        "    select: string\n",
        "        additional query to limit the result\n",
        "        example: query='female==1'\n",
        "         \n",
        "    dtype=dictionary of dtypes (column names from the schema)\n",
        "        speficy the dtypes of the columns\n",
        "    \"\"\"\n",
        "    \n",
        "    dfs=[]\n",
        "    \n",
        "    # allow user to input a list of ids (instead of dicts with separate ids \n",
        "    # for every (file, key) combination\n",
        "    # if it is a list, every file select for these ids\n",
        "    #\n",
        "    \n",
        "    if (isinstance(ids, list)) or (isinstance(ids, set)):\n",
        "        ids_new={}\n",
        "        for file, keys in file_keys.items():\n",
        "            for key in keys:\n",
        "                ids_new[(file, key)] = ids\n",
        "        ids = ids_new\n",
        "        \n",
        "    if schema:\n",
        "        oldvars = {var for varlist in schema.values() for var in varlist}\n",
        "        old_to_new = dict( (v,k) for k in schema for v in schema[k] )\n",
        "    \n",
        "    for file, keys in file_keys.items():\n",
        "        for key in keys:\n",
        "            header = pd.read_hdf(file, key, start=0, stop=1)\n",
        "            header = set(header.columns)\n",
        "            \n",
        "            if columns:        \n",
        "                oldvars = {var for k, varlist in schema.items() \n",
        "                            if k in columns \n",
        "                            for var in varlist} \n",
        "                \n",
        "                use_columns = header.intersection(oldvars)\n",
        "            else:\n",
        "                use_columns = header\n",
        "                \n",
        "            store= pd.HDFStore(file)\n",
        "            #hmm, should not use pid here, use old pid (since pid may not exist)\n",
        "            #better, but not perfect since there may two is columns in some files?\n",
        "            #to solve this: need \"true\" file schema. one for each file\n",
        "            #or make user input a pid dictionary?\n",
        "            \n",
        "            #local_pid_col = set(old_to_new['pid']).intersection(header)\n",
        "                        \n",
        "            all_ids = store.select_column(key, id_col)\n",
        "            selected_ids = ids[(file, key)]\n",
        "            idarray = all_ids.isin(selected_ids)\n",
        "            \n",
        "            df = pd.read_hdf(file, key, columns=use_columns, where=idarray)\n",
        "            \n",
        "            if schema:\n",
        "                df = df.rename(columns=old_to_new)\n",
        "                     \n",
        "            if select:\n",
        "                df = df.query(select)\n",
        "            dfs.append(df)\n",
        "            \n",
        "    dfs=pd.concat(dfs)\n",
        "    return dfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RepyTXsJ1i-g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2imtqsYY1i73"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAtxswBi1i5A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fPpqdCu1i2I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}